{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12ce5ebd-a940-438d-aa6a-ca60640eae34",
   "metadata": {},
   "source": [
    "### Generating Features for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9312c64c-d5a6-4250-8329-ccb520bdd083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "494e82c7-792e-4923-977d-8ad5cc4a5b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "financial_news = load_dataset('financial_phrasebank', 'sentences_50agree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28fa193a-66d4-4256-9d17-7c4f2846ee9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 4846\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b27f530-f66d-4c4f-b328-244c6893af7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label\n",
       "0  According to Gran , the company has no plans t...      1\n",
       "1  Technopolis plans to develop in stages an area...      1\n",
       "2  The international electronic industry company ...      0\n",
       "3  With the new production plant the company woul...      2\n",
       "4  According to the company 's updated strategy f...      2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(financial_news['train'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b661865c-c51e-45cd-8129-5e8f97f1fc01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec348166ada405ea2adfb2a32d20f0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8cdafe6f5334bfeadb6264bceec4b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c3440b5b6a4607b49aa5f6f4cca161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a0d5d226db4e48970cdac7998dc415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pre_trained_model_name = 'bert-base-cased'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(pre_trained_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58d965a8-838a-49db-9794-4d1c1afb46ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1792,\n",
       " 1106,\n",
       " 13529,\n",
       " 117,\n",
       " 1103,\n",
       " 1419,\n",
       " 1144,\n",
       " 1185,\n",
       " 2714,\n",
       " 1106,\n",
       " 1815,\n",
       " 1155,\n",
       " 1707,\n",
       " 1106,\n",
       " 2733,\n",
       " 117,\n",
       " 1780,\n",
       " 1115,\n",
       " 1110,\n",
       " 1187,\n",
       " 1103,\n",
       " 1419,\n",
       " 1110,\n",
       " 2898,\n",
       " 119]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids( tokenizer.tokenize( data.sentence[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4767684b-960a-42e2-8079-66181223ace4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[SEP]', 102)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sep_token, tokenizer.sep_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa40c7c-38d1-4bf8-88c4-8042bf57a34a",
   "metadata": {},
   "source": [
    "### Implementing and Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46014c4e-848b-4f39-ad8e-ed8ee0227ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer.encode_plus(\n",
    "    tokenizer.tokenize( data.sentence[0]),\n",
    "    max_length=32,\n",
    "    add_special_tokens=True,\n",
    "    return_token_type_ids=False,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8997993-d358-42b2-b56b-79563dda4603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b53fa6b-9cfb-43b2-88c8-f011b4a4b93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'According',\n",
       " 'to',\n",
       " 'Gran',\n",
       " ',',\n",
       " 'the',\n",
       " 'company',\n",
       " 'has',\n",
       " 'no',\n",
       " 'plans',\n",
       " 'to',\n",
       " 'move',\n",
       " 'all',\n",
       " 'production',\n",
       " 'to',\n",
       " 'Russia',\n",
       " ',',\n",
       " 'although',\n",
       " 'that',\n",
       " 'is',\n",
       " 'where',\n",
       " 'the',\n",
       " 'company',\n",
       " 'is',\n",
       " 'growing',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b953feeb-ae27-493d-a01b-bf4967101592",
   "metadata": {},
   "source": [
    "### Developing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58de27a6-3dd4-4be1-aa01-a12aaec5f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinPhraseDataset(Dataset):\n",
    "\n",
    "    def __init__(self, reviews, targets, tokenizer, max_len):\n",
    "        self.reviews = reviews\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        review = str(self.reviews[idx])\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens = True,\n",
    "            max_length = self.max_len,\n",
    "            return_token_type_ids = False,\n",
    "            padding = True,\n",
    "            truncation = True,\n",
    "            return_attention_mask = True,\n",
    "            return_tensors = 'pt'    \n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'review_text' : review,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask' : encoding['attention_mask'].flatten(),\n",
    "            'targets' : torch.tensor(target, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52163b63-f515-421b-bb90-c49f0b3d740e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b50f3fe-40a9-4a74-b3cd-f27994226136",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(data, test_size=.1, random_state=391)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36c45b20-9557-40e3-b7f2-d4b673539831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4361, 2), (485, 2))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d070094-49f0-4188-91bc-a04318693492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "    ds = FinPhraseDataset(\n",
    "        reviews= data.sentence.to_numpy(),\n",
    "        targets= data.label.to_numpy(),\n",
    "        tokenizer= tokenizer,\n",
    "        max_len = max_len\n",
    "    )\n",
    "\n",
    "    return DataLoader( ds, batch_size=batch_size, num_workers=4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cad20d6-829e-42e2-bbac-df2d7d390086",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 90\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "863a7c34-cb20-4336-8c80-cf0a7e172e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_data_loader(df_train, tokenizer, max_len, batch_size)\n",
    "test_loader = create_data_loader(df_test, tokenizer, max_len, batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
