{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adf7614d-3ba5-4339-a8cb-c4bc21c20566",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50,120,229)\"> Principles of Statistical Learning - Term Paper Code Implementation </font>\n",
    "\n",
    "Name: Sifael Sebastian Ndandala <br>\n",
    "Course: Principles of Statistical Learning <br>\n",
    "Date: May 28th, 2024\n",
    "\n",
    "#### Summary \n",
    "\n",
    "This notebook contains the implementation of the Final Term Paper for the Principles of Statistical Learning Course, Spring 2024. It is intended to reflect the work in the final term paper through the use of Python. The sections are broken down into the following parts:\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "#### <font style=\"color:rgb(50,120,229)\"> [1. Personal Motivation and Learning Objectives](Personal-Motivation-and-Learning-Objectives) </font>\n",
    "\n",
    "A personal articulation outlining the motivation to work on the dataset for the term paper. This includes a general description of the dataset including metadata, dimensions of the data and the eventual goal of the dataset for the project.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94dbaaa-8a58-4d4d-ac19-15a23485b371",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### <font style=\"color:rgb(50,120,229)\"> 1. Personal Motivation  </font>\n",
    "\n",
    "Natural Language Processing (NLP) is a domain of significant relevance in both industry and academic research and is increasingly becoming indispensable in shaping how we communicate and interact with information and each other across many aspects of our lives. With advanced tools and platforms like ChatGPT, NLP technologies are enabling machines to understand, interpret, and respond to human languages in ways previously unimaginable. This transformative power, which is increasingly integrated into the technological tools we use every day, is poised to enhance our experiences, improved our productivity and efficiency across all domains.\n",
    "\n",
    "For a Data Engineer, the importance of developing expertise in Natural Language Processing cannot be overstated. As data infrastructures grow more complex and the volume of unstructured text data increases, the ability to implement and manage NLP-centered solutions can greatly enhance a data engineer's capability to extract meaningful information from vast datasets. Furthermore, as businesses increasingly adopt NLP technologies, the role of a Data Engineer in implementing NLP solutions becomes more critical. This includes designing and optimizing data processes and analysis that are versatile, scalable and efficient to meet the needs of this dynamic field.\n",
    "\n",
    "\n",
    "To that end, I have chosen to use Google Playstore App Reviews for this term paper. This dataset contains 280,000 verified user reviews across 395 Google Store apps from 23 app categories, providing a rich source of unstructured textual data for analysis and application of NLP techniques. The primary objective of this datasets is to develop a classifcation algorithm that can predict the rating of a given review. Such a classication tasks offers opportunities to develop features from text and build a model that can generate insights on new app reviews. The dataset is available through the curated Hugging Face Datasets Ecosystem: https://huggingface.co/datasets/app_reviews\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ca2d50-f681-4601-8689-ce81b513b89b",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### <font style=\"color:rgb(50,120,229)\"> 1.2. Learning Objectives </font>\n",
    "\n",
    "The learning objectives for this project are closed aligned with my decision to select a NLP dataset. Specifically, there are four learning objectives:\n",
    "\n",
    "\n",
    "##### <font style=\"color:rgb(50,120,229)\"> 1.2.1. Deepen my Understanding of NLP </font>\n",
    "\n",
    "This project aims to deepen my understanding of NLP (NLP), focusing on mastering core concepts of feature generation such as BOW, TIFDF and WordVectors and their respective effectiveness in performing textual analysis. Futhermore, these foundational concepts are building blocks for more complex applications such as classification and text generation.\n",
    "\n",
    "\n",
    "##### <font style=\"color:rgb(50,120,229)\"> 1.2.2. Developing Computational Competencies in NLP Tools </font>\n",
    "\n",
    "Aligned with my first objective, I aim to use this project to develop computational competencies in NLP tools. NLP is notoriously computationally expensive and requires advanced programming concepts such as parallel and distributed computing to manage data processing, analysis, and machine learning. I intend on using tools such as PySpark, Dask, and core Python to efficiently handle large-scale data, leveraging their capabilities to optimize the performance of NLP models through parallel processing and streamlined data workflows.\n",
    "\n",
    "##### <font style=\"color:rgb(50,120,229)\"> 1.2.3. Application of Statistical Inference on Textual Data </font>\n",
    "\n",
    "Finally, I aim to apply the concepts developed in the Principles of Statistical Learning to develop classications algorithms that can predict the sentiment of the review for a given app given the choice of words provided by a user. This will materialize concepts such as probability distributions and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec18ddb1-fac6-4881-9cf7-bc068bf20351",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### <font style=\"color:rgb(50,120,229)\"> 1.3. Data Acquisition </font>\n",
    "\n",
    "The Google PlayStore Reviews dataset is the largest dataset of Android applications across 23 app categories. Collectively, the dataset contains approximately 280,000 pieces of feedback from users for 395 apps on the Google PlayStore. The dataset was chosen in part because of the robust set of reviews across different categories. The metadata of the dataset is provided below:\n",
    "\n",
    "\n",
    "#### <font style=\"color:rgb(50,120,229)\"> Dataset Metadata </font>\n",
    "\n",
    "```SQL\n",
    "package_name : Name of the Software Application Package\n",
    "review : Message of the user\n",
    "date : date when the user posted the review\n",
    "star : rating provied by the user for the application\n",
    "```\n",
    "\n",
    "### <font style=\"color:rgb(50,120,229)\"> Downloading the Data </font>\n",
    "\n",
    "The dataset is publicly available through multiple sources that offer specific versions of the data. The comprehensive data is accessible via GitHub and the Hugging Face Dataset Library. Due to the size of the dataset, I opted to use the Hugging Face dataset to download the data directly into memory for efficient data processing and analysis.\n",
    "\n",
    "Github: https://github.com/sealuzh/user_quality/tree/master <br>\n",
    "Hugging Face: https://huggingface.co/datasets/app_reviews\n",
    "\n",
    "```python\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"app_reviews\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d6c567-75e8-473a-bd46-8154799e39bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
